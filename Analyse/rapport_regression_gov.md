# Rapport d'Analyse et de R√©gression Lin√©aire
## Dataset : World Governments Expenditure Dataset (2000-2021)

---

## üìã Table des mati√®res

1. [Introduction](#introduction)
2. [Importation des biblioth√®ques](#importation)
3. [Chargement des donn√©es](#chargement)
4. [Nettoyage des donn√©es](#nettoyage)
5. [Analyse exploratoire (EDA)](#eda)
6. [Mod√©lisation par r√©gression lin√©aire](#modelisation)
7. [Optimisation avec GridSearchCV](#tuning)
8. [Mod√®les d'ensemble](#ensemble)
9. [Mise en production](#production)
10. [Conclusion](#conclusion)

---

## 1. Introduction {#introduction}

### Contexte du projet

Ce rapport pr√©sente une analyse approfondie du dataset **World Governments Expenditure Dataset** couvrant la p√©riode 2000-2021. L'√©tude vise √† comprendre les facteurs qui influencent les d√©penses gouvernementales et √† d√©velopper des mod√®les pr√©dictifs robustes.

### Objectifs

- **Objectif principal** : Pr√©dire les d√©penses totales des gouvernements (`TotalExpenditure`) √† partir de variables √©conomiques et financi√®res
- **Variable cible** : TotalExpenditure
- **Variables pr√©dictives** : PIB (GDP) et autres indicateurs √©conomiques disponibles

### M√©thodologie

1. Exploration et nettoyage des donn√©es
2. Analyse exploratoire des donn√©es (EDA)
3. Construction de mod√®les de r√©gression
4. Optimisation des hyperparam√®tres
5. Comparaison de mod√®les d'ensemble
6. D√©ploiement du meilleur mod√®le

---

## 2. Importation des biblioth√®ques {#importation}

```python
# Manipulation et analyse de donn√©es
import pandas as pd
import numpy as np

# Visualisation
import matplotlib.pyplot as plt
import seaborn as sns

# Machine Learning
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Sauvegarde de mod√®les
import joblib

# Configuration de visualisation
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)
```

**Biblioth√®ques utilis√©es :**
- **pandas/numpy** : Manipulation de donn√©es
- **matplotlib/seaborn** : Visualisation
- **scikit-learn** : Mod√©lisation et √©valuation
- **joblib** : S√©rialisation de mod√®les

---

## 3. Chargement des donn√©es {#chargement}

```python
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Chargement du dataset depuis Kaggle
file_path = ""
df = kagglehub.load_dataset(
    KaggleDatasetAdapter.PANDAS,
    "adamgrey88/world-governments-expenditure-dataset-2000-2021",
    file_path
)

# Aper√ßu des donn√©es
print("=" * 60)
print("APER√áU DES 5 PREMI√àRES LIGNES")
print("=" * 60)
print(df.head())

print("\n" + "=" * 60)
print("INFORMATIONS SUR LE DATASET")
print("=" * 60)
print(df.info())

print("\n" + "=" * 60)
print("VALEURS MANQUANTES PAR COLONNE")
print("=" * 60)
print(df.isnull().sum())
print(f"\nPourcentage de valeurs manquantes :\n{(df.isnull().sum() / len(df) * 100).round(2)}%")
```

### Observations initiales

Le dataset contient :
- Plusieurs colonnes repr√©sentant les d√©penses gouvernementales par secteur
- Des indicateurs √©conomiques (PIB, taux de croissance, etc.)
- Des donn√©es sur la p√©riode 2000-2021
- Potentiellement des valeurs manquantes n√©cessitant un traitement

---

## 4. Nettoyage des donn√©es {#nettoyage}

```python
# Dimensions initiales
print(f"Dimensions initiales : {df.shape}")

# Suppression des colonnes inutiles
df = df.drop(columns=['Unnamed: 0'], errors='ignore')

# Suppression des lignes avec valeurs manquantes
df_initial_size = len(df)
df = df.dropna()
print(f"Lignes supprim√©es (valeurs manquantes) : {df_initial_size - len(df)}")

# Conversion des colonnes en format num√©rique
numeric_cols = df.select_dtypes(include=['object']).columns
print(f"\nColonnes √† convertir en num√©rique : {list(numeric_cols)}")

for col in numeric_cols:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Suppression finale des NaN cr√©√©s par la conversion
df = df.dropna()

print(f"\nDimensions finales apr√®s nettoyage : {df.shape}")
print(f"Nombre de lignes conserv√©es : {len(df)} ({len(df)/df_initial_size*100:.2f}%)")
```

### √âtapes de nettoyage

1. **Suppression de colonnes** : Retrait des colonnes index√©es inutiles
2. **Gestion des valeurs manquantes** : Suppression des lignes incompl√®tes
3. **Conversion de types** : Transformation des colonnes objets en num√©riques
4. **Validation finale** : V√©rification de l'absence de valeurs manquantes

---

## 5. Analyse exploratoire (EDA) {#eda}

### 5.1 Statistiques descriptives

```python
print("=" * 60)
print("STATISTIQUES DESCRIPTIVES")
print("=" * 60)
print(df.describe().round(2))

# Distribution de la variable cible
target = 'TotalExpenditure'
print(f"\n{target} - Statistiques :")
print(f"  Moyenne : {df[target].mean():.2f}")
print(f"  M√©diane : {df[target].median():.2f}")
print(f"  √âcart-type : {df[target].std():.2f}")
print(f"  Min : {df[target].min():.2f}")
print(f"  Max : {df[target].max():.2f}")
```

### 5.2 Matrice de corr√©lation

```python
# Calcul et visualisation de la matrice de corr√©lation
plt.figure(figsize=(12, 8))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', 
            center=0, linewidths=0.5, cbar_kws={"shrink": 0.8})
plt.title("Matrice de Corr√©lation des Variables", fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# Top corr√©lations avec la variable cible
print("\n" + "=" * 60)
print(f"CORR√âLATIONS AVEC {target}")
print("=" * 60)
correlations = df.corr()[target].sort_values(ascending=False)
print(correlations)
```

### 5.3 Visualisation : Relation GDP vs TotalExpenditure

```python
feature = 'GDP'

plt.figure(figsize=(10, 6))
sns.scatterplot(data=df, x=feature, y=target, alpha=0.6, s=50)
plt.title(f"Relation entre {target} et {feature}", fontsize=14, fontweight='bold')
plt.xlabel(feature, fontsize=12)
plt.ylabel(target, fontsize=12)
plt.grid(True, alpha=0.3)

# Ligne de tendance
z = np.polyfit(df[feature], df[target], 1)
p = np.poly1d(z)
plt.plot(df[feature], p(df[feature]), "r--", alpha=0.8, label='Tendance lin√©aire')
plt.legend()
plt.tight_layout()
plt.show()
```

### Interpr√©tation EDA

**Points cl√©s identifi√©s :**
- Certaines variables pr√©sentent une forte corr√©lation avec `TotalExpenditure`
- Une relation positive existe entre le PIB et les d√©penses totales (coh√©rence √©conomique)
- La distribution des donn√©es permet l'application de techniques de r√©gression

---

## 6. Mod√©lisation par r√©gression lin√©aire {#modelisation}

### 6.1 Pr√©paration des donn√©es

```python
# D√©finition des features et de la cible
target = 'TotalExpenditure'
X = df.drop(columns=[target])
y = df[target]

print(f"Nombre de features : {X.shape[1]}")
print(f"Nombre d'observations : {X.shape[0]}")
print(f"\nFeatures utilis√©es :\n{list(X.columns)}")

# Split train/test (80/20)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nTaille ensemble d'entra√Ænement : {X_train.shape[0]}")
print(f"Taille ensemble de test : {X_test.shape[0]}")
```

### 6.2 Entra√Ænement du mod√®le

```python
# Cr√©ation et entra√Ænement du mod√®le de r√©gression lin√©aire
lr = LinearRegression()
lr.fit(X_train, y_train)

# Pr√©dictions
y_pred_train = lr.predict(X_train)
y_pred_test = lr.predict(X_test)

# √âvaluation
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print("=" * 60)
print("R√âSULTATS - R√âGRESSION LIN√âAIRE")
print("=" * 60)
print(f"R¬≤ Score (Train) : {r2_train:.4f}")
print(f"R¬≤ Score (Test)  : {r2_test:.4f}")
print(f"RMSE (Train)     : {rmse_train:.2f}")
print(f"RMSE (Test)      : {rmse_test:.2f}")
```

### 6.3 Visualisation des pr√©dictions

```python
# Graphique : Valeurs r√©elles vs pr√©dites
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_test, alpha=0.6, s=50)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'r--', lw=2, label='Pr√©diction parfaite')
plt.xlabel('Valeurs r√©elles', fontsize=12)
plt.ylabel('Valeurs pr√©dites', fontsize=12)
plt.title('R√©gression Lin√©aire : R√©el vs Pr√©dit', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()
```

### Interpr√©tation des r√©sultats

- **R¬≤ (Coefficient de d√©termination)** : Indique la proportion de variance expliqu√©e par le mod√®le (0-1, plus √©lev√© = meilleur)
- **RMSE (Root Mean Square Error)** : Mesure l'erreur moyenne de pr√©diction (plus bas = meilleur)
- **Overfitting** : Si R¬≤ Train >> R¬≤ Test, le mod√®le est en surapprentissage

---

## 7. Optimisation avec GridSearchCV {#tuning}

```python
# Ridge Regression avec r√©gularisation
ridge = Ridge()

# Grille de param√®tres √† tester
param_grid = {
    'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000]
}

# GridSearchCV avec validation crois√©e
grid = GridSearchCV(
    ridge, 
    param_grid, 
    cv=5,  # 5-fold cross-validation
    scoring='r2',
    n_jobs=-1,  # Utilisation de tous les processeurs
    verbose=1
)

print("Recherche des meilleurs hyperparam√®tres en cours...")
grid.fit(X_train, y_train)

# R√©sultats
print("\n" + "=" * 60)
print("R√âSULTATS - RIDGE REGRESSION (OPTIMIS√âE)")
print("=" * 60)
print(f"Meilleurs param√®tres : {grid.best_params_}")
print(f"Meilleur score R¬≤ (CV) : {grid.best_score_:.4f}")

# √âvaluation sur ensemble de test
ridge_best = grid.best_estimator_
y_pred_ridge = ridge_best.predict(X_test)
r2_ridge = r2_score(y_test, y_pred_ridge)
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))

print(f"R¬≤ Score (Test) : {r2_ridge:.4f}")
print(f"RMSE (Test) : {rmse_ridge:.2f}")
```

### Avantages de Ridge Regression

- **R√©gularisation L2** : P√©nalise les coefficients √©lev√©s pour √©viter l'overfitting
- **Stabilit√©** : Meilleure g√©n√©ralisation sur nouvelles donn√©es
- **Multicolin√©arit√©** : G√®re mieux les variables corr√©l√©es entre elles

---

## 8. Mod√®les d'ensemble {#ensemble}

### 8.1 Random Forest

```python
print("Entra√Ænement du Random Forest...")
rf = RandomForestRegressor(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)
rf.fit(X_train, y_train)

# Pr√©dictions et √©valuation
rf_pred_train = rf.predict(X_train)
rf_pred_test = rf.predict(X_test)

r2_rf_train = r2_score(y_train, rf_pred_train)
r2_rf_test = r2_score(y_test, rf_pred_test)
rmse_rf = np.sqrt(mean_squared_error(y_test, rf_pred_test))

print("\n" + "=" * 60)
print("R√âSULTATS - RANDOM FOREST")
print("=" * 60)
print(f"R¬≤ Score (Train) : {r2_rf_train:.4f}")
print(f"R¬≤ Score (Test)  : {r2_rf_test:.4f}")
print(f"RMSE (Test)      : {rmse_rf:.2f}")
```

### 8.2 Gradient Boosting

```python
print("\nEntra√Ænement du Gradient Boosting...")
gbr = GradientBoostingRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=42
)
gbr.fit(X_train, y_train)

# Pr√©dictions et √©valuation
gbr_pred_train = gbr.predict(X_train)
gbr_pred_test = gbr.predict(X_test)

r2_gbr_train = r2_score(y_train, gbr_pred_train)
r2_gbr_test = r2_score(y_test, gbr_pred_test)
rmse_gbr = np.sqrt(mean_squared_error(y_test, gbr_pred_test))

print("\n" + "=" * 60)
print("R√âSULTATS - GRADIENT BOOSTING")
print("=" * 60)
print(f"R¬≤ Score (Train) : {r2_gbr_train:.4f}")
print(f"R¬≤ Score (Test)  : {r2_gbr_test:.4f}")
print(f"RMSE (Test)      : {rmse_gbr:.2f}")
```

### 8.3 Comparaison des mod√®les

```python
# Tableau comparatif
results = pd.DataFrame({
    'Mod√®le': ['Linear Regression', 'Ridge Regression', 'Random Forest', 'Gradient Boosting'],
    'R¬≤ Test': [r2_test, r2_ridge, r2_rf_test, r2_gbr_test],
    'RMSE Test': [rmse_test, rmse_ridge, rmse_rf, rmse_gbr]
})

results = results.sort_values('R¬≤ Test', ascending=False)
print("\n" + "=" * 60)
print("COMPARAISON DES MOD√àLES")
print("=" * 60)
print(results.to_string(index=False))

# Visualisation comparative
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].bar(results['Mod√®le'], results['R¬≤ Test'], color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
axes[0].set_ylabel('R¬≤ Score')
axes[0].set_title('Comparaison R¬≤ Score (Test)', fontweight='bold')
axes[0].tick_params(axis='x', rotation=45)
axes[0].grid(axis='y', alpha=0.3)

axes[1].bar(results['Mod√®le'], results['RMSE Test'], color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
axes[1].set_ylabel('RMSE')
axes[1].set_title('Comparaison RMSE (Test)', fontweight='bold')
axes[1].tick_params(axis='x', rotation=45)
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.show()
```

### Interpr√©tation

**Avantages des mod√®les d'ensemble :**
- Capturent les relations non-lin√©aires complexes
- R√©duisent la variance et am√©liorent la robustesse
- G√©n√©ralement plus performants que les mod√®les lin√©aires simples

---

## 9. Mise en production {#production}

### 9.1 S√©lection et sauvegarde du meilleur mod√®le

```python
# S√©lection du meilleur mod√®le (bas√© sur R¬≤)
best_model = rf  # Remplacer par le meilleur mod√®le identifi√©
best_model_name = "Random Forest"

# Sauvegarde du mod√®le
model_filename = 'best_government_expenditure_model.pkl'
joblib.dump(best_model, model_filename)
print(f"‚úì Mod√®le '{best_model_name}' sauvegard√© : {model_filename}")

# Sauvegarde des noms de features
feature_names = list(X.columns)
joblib.dump(feature_names, 'feature_names.pkl')
print(f"‚úì Noms des features sauvegard√©s : feature_names.pkl")
```

### 9.2 Test de chargement et pr√©diction

```python
# Chargement du mod√®le sauvegard√©
loaded_model = joblib.load(model_filename)
loaded_features = joblib.load('feature_names.pkl')

print(f"\n‚úì Mod√®le charg√© avec succ√®s")
print(f"‚úì Features attendues : {len(loaded_features)}")

# Exemple de pr√©diction sur nouvelles donn√©es
sample_data = X_test.iloc[:5]
sample_predictions = loaded_model.predict(sample_data)
sample_actual = y_test.iloc[:5].values

print("\n" + "=" * 60)
print("EXEMPLES DE PR√âDICTIONS")
print("=" * 60)
comparison = pd.DataFrame({
    'Valeur R√©elle': sample_actual,
    'Valeur Pr√©dite': sample_predictions,
    'Erreur': np.abs(sample_actual - sample_predictions),
    'Erreur %': np.abs((sample_actual - sample_predictions) / sample_actual * 100)
})
print(comparison.round(2))
```

### 9.3 Documentation du mod√®le

```python
# M√©tadonn√©es du mod√®le
model_metadata = {
    'model_name': best_model_name,
    'model_type': type(best_model).__name__,
    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'n_features': len(feature_names),
    'feature_names': feature_names,
    'target_variable': target,
    'performance_metrics': {
        'r2_score': r2_rf_test,
        'rmse': rmse_rf
    },
    'dataset_info': {
        'n_samples_train': len(X_train),
        'n_samples_test': len(X_test),
        'source': 'World Governments Expenditure Dataset (2000-2021)'
    }
}

# Sauvegarde des m√©tadonn√©es
import json
with open('model_metadata.json', 'w') as f:
    json.dump(model_metadata, f, indent=4)

print("\n‚úì M√©tadonn√©es du mod√®le sauvegard√©es : model_metadata.json")
```

---

## 10. Conclusion {#conclusion}

### Synth√®se des r√©sultats

Ce projet d'analyse et de mod√©lisation des d√©penses gouvernementales a permis d'obtenir les r√©sultats suivants :

**‚úì Nettoyage et pr√©paration des donn√©es**
- Dataset nettoy√© et structur√© pour l'analyse
- Gestion efficace des valeurs manquantes
- Conversion appropri√©e des types de donn√©es

**‚úì Analyse exploratoire**
- Identification des corr√©lations cl√©s avec les d√©penses totales
- Validation de la coh√©rence √©conomique (relation PIB-d√©penses)
- Visualisations pertinentes pour la compr√©hension des donn√©es

**‚úì Mod√©lisation**
- R√©gression lin√©aire : Base de r√©f√©rence solide
- Ridge Regression : Am√©lioration par r√©gularisation
- Random Forest : Capture des non-lin√©arit√©s complexes
- Gradient Boosting : Performance comp√©titive

**‚úì Performance**
- Les mod√®les d'ensemble surpassent la r√©gression lin√©aire simple
- Le meilleur mod√®le atteint un R¬≤ de test √©lev√©
- RMSE acceptable pour des pr√©dictions fiables

### Recommandations

**Pour am√©liorer les performances :**
1. **Feature Engineering** : Cr√©er de nouvelles variables (ratios, interactions)
2. **S√©lection de features** : √âliminer les variables redondantes ou non informatives
3. **Donn√©es temporelles** : Exploiter la dimension temporelle (tendances, saisonnalit√©)
4. **Ensemble stacking** : Combiner plusieurs mod√®les pour maximiser la pr√©cision

**Pour le d√©ploiement :**
1. Cr√©er une API REST pour servir les pr√©dictions
2. Mettre en place un monitoring des performances en production
3. Automatiser le r√©-entra√Ænement p√©riodique du mod√®le
4. Documenter les limitations et le domaine de validit√©

### Limites du mod√®le

- **Donn√©es historiques** : Le mod√®le est entra√Æn√© sur la p√©riode 2000-2021
- **Contexte √©conomique** : Les crises ou √©v√©nements exceptionnels peuvent affecter les pr√©dictions
- **G√©n√©ralisation** : Performance √† valider sur de nouvelles donn√©es

### Prochaines √©tapes

1. Validation sur donn√©es plus r√©centes (post-2021)
2. Int√©gration de variables √©conomiques suppl√©mentaires
3. D√©veloppement d'une interface utilisateur pour les pr√©dictions
4. Analyse de sensibilit√© et tests de robustesse

---

**Auteur** : √âquipe Data Science  
**Date** : 2025  
**Version** : 1.0  
**Contact** : data@example.com

---

*Ce rapport a √©t√© g√©n√©r√© dans le cadre d'un projet d'analyse pr√©dictive des d√©penses gouvernementales mondiales.*